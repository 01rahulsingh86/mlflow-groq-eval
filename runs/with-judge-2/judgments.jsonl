{"prompt": "Return just the result of 15*3.", "prediction": "45", "reference": "45", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "What is 2+2? Return only the number.", "prediction": "4", "reference": "4", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "What is 10 divided by 4? Round to 2 decimals", "prediction": "10 divided by 4 is 2.5.", "reference": "2.50", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Name the capital of France. Return only the city.", "prediction": "Paris.", "reference": "Paris", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Name the capital of Japan. Return only the city.", "prediction": "Tokyo", "reference": "Tokyo", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Reverse the string 'hello'.", "prediction": "The reverse of 'hello' is 'olleh'.", "reference": "olleh", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Uppercase the word 'chatgpt'.", "prediction": "CHATGPT", "reference": "CHATGPT", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Lowercase the word 'MiXeD'.", "prediction": "mixed", "reference": "mixed", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "How many letters are in 'banana'? Return only the number.", "prediction": "6", "reference": "6", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Give the first three letters of 'elephant'.", "prediction": "The first three letters of 'elephant' are 'e-l-e'.", "reference": "ele", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Is 'racecar' a palindrome? Answer yes or no.", "prediction": "Yes.", "reference": "yes", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Extract the domain from 'https://www.openai.com/blog'. Return just the domain.", "prediction": "openai.com", "reference": "openai.com", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Sort this list alphabetically and return as a comma list: pear, apple, banana", "prediction": "apple, banana, pear", "reference": "apple, banana, pear", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Join the words 'blue' and 'sky' with a hyphen.", "prediction": "Blue-sky.", "reference": "blue-sky", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Return JSON exactly with key 'a' and value 1.", "prediction": "```json\n{\n  \"a\": 1\n}\n```", "reference": "{\\a\\\":1}\"", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Extract only the digits from 'abc123def'.", "prediction": "The digits are: 1 2 3", "reference": "123", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Remove vowels from 'computer'.", "prediction": "cmptr.", "reference": "cmptr", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Plural of 'city'.", "prediction": "The plural of 'city' is 'cities'.", "reference": "cities", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Give the antonym of 'hot' (one word).", "prediction": "Cold.", "reference": "cold", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Convert 100 centimeters to meters. Return only the number.", "prediction": "1", "reference": "1", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "How many seconds are in 5 minutes? Return only the number.", "prediction": "300", "reference": "300", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Reformat the date '12/31/2023' to YYYY-MM-DD.", "prediction": "The date '12/31/2023' in YYYY-MM-DD format is 2023-12-31.", "reference": "2023-12-31", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Extract the country code from '+1-415-555-1234'. Return only the number.", "prediction": "+1", "reference": "1", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Count the words in 'to be or not to be'. Return only the number.", "prediction": "6", "reference": "6", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Which is larger: 0.5 or 0.05? Return the number.", "prediction": "0.5", "reference": "0.5", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Is 17 a prime number? Answer yes or no.", "prediction": "Yes.", "reference": "yes", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Return the first name from 'Ada Lovelace'.", "prediction": "Ada.", "reference": "Ada", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Return the last 4 characters of 'ABCDEFGHIJ'.", "prediction": "The last 4 characters of 'ABCDEFGHIJ' are 'HIJ'.", "reference": "GHIJ", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Remove all spaces from 'a b  c'.", "prediction": "a b c becomes a b c -> a b c without spaces is 'abc'.", "reference": "abc", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Convert 32°F to °C. Round to 1 decimal and return only the number.", "prediction": "0.0", "reference": "0.0", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Extract the file extension from 'report.pdf'.", "prediction": "The file extension is '.pdf'.", "reference": "pdf", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Return the third item from this list: red,green,blue,yellow", "prediction": "The third item from the list is: blue.", "reference": "blue", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Convert 'Hello World' to snake_case.", "prediction": "The 'Hello World' string in snake_case is 'hello_world'.", "reference": "hello_world", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Return the sum of the digits in 90210. Return only the number.", "prediction": "9 + 0 + 2 + 1 + 0 = 12", "reference": "12", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Return the number of unique letters in 'Mississippi'. Return only the number.", "prediction": "8", "reference": "4", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
{"prompt": "Give the ISO 3166-1 alpha-2 code for United States.", "prediction": "The ISO 3166-1 alpha-2 code for the United States is US.", "reference": "US", "coherence": 0.0, "relevance": 0.0, "groundedness": 0.0, "rationale": "judge error: '\"coherence\"'"}
